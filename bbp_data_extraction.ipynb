{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1f0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from extract_dates import dates\n",
    "from extract_viewers import viewers\n",
    "from extract_episode import episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8219f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting data from the web\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_The_Big_Bang_Theory_episodes'\n",
    "headers = {\n",
    "    \"User-Agent\": \"user agent\"}  # Please substitute \"user agent\" with your own one\n",
    "\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "total_episodes = []\n",
    "total_viewers = []\n",
    "total_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cccab66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data for Season 1 (rows in Season's 1 table = 17)\n",
    "\n",
    "episodes_1_int = episodes(soup, 0, 17)\n",
    "viewers_1_float = viewers(soup, 0, 17)\n",
    "air_dates_1 = dates(soup, 0, 17)\n",
    "\n",
    "total_episodes.append(episodes_1_int)\n",
    "total_viewers.append(viewers_1_float)\n",
    "total_dates.append(air_dates_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112d4c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes for Season 1: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Viewers (millions) for Season 1: [9.52, 8.58, 8.36, 8.15, 8.81, 8.92, 9.68, 9.32, 9.11, 8.63, 8.68, 7.69, 7.51, 8.07, 7.38, 7.79, 7.34]\n",
      "Air dates for Season 1: ['2007-09-24', '2007-10-01', '2007-10-08', '2007-10-15', '2007-10-22', '2007-10-29', '2007-11-05', '2007-11-12', '2008-03-17', '2008-03-24', '2008-03-31', '2008-04-14', '2008-04-21', '2008-04-28', '2008-05-05', '2008-05-12', '2008-05-19']\n"
     ]
    }
   ],
   "source": [
    "# Example of first extraction\n",
    "\n",
    "print(f'Episodes for Season 1: {episodes_1_int}')\n",
    "print(f'Viewers (millions) for Season 1: {viewers_1_float}')\n",
    "print(f'Air dates for Season 1: {air_dates_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f51fd260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can proceed with the scraping for all season's data:\n",
    "\n",
    "# Extracting data for Season 2 (rows in Season's 2 table = 23)\n",
    "\n",
    "episodes_2_int = episodes(soup, 1, 23)\n",
    "viewers_2_float = viewers(soup, 1, 23)\n",
    "air_dates_2 = dates(soup, 1, 23)\n",
    "\n",
    "total_episodes.append(episodes_2_int)\n",
    "total_viewers.append(viewers_2_float)\n",
    "total_dates.append(air_dates_2)\n",
    "\n",
    "# Extracting data for Season 3 (rows in Season's 3 table = 23)\n",
    "\n",
    "episodes_3_int = episodes(soup, 2, 23)\n",
    "viewers_3_float = viewers(soup, 2, 23)\n",
    "air_dates_3 = dates(soup, 2, 23)\n",
    "\n",
    "total_episodes.append(episodes_3_int)\n",
    "total_viewers.append(viewers_3_float)\n",
    "total_dates.append(air_dates_3)\n",
    "\n",
    "# Extracting data for Season 4 (rows in Season's 4 table = 24)\n",
    "\n",
    "episodes_4_int = episodes(soup, 3, 24)\n",
    "viewers_4_float = viewers(soup, 3, 24)\n",
    "air_dates_4 = dates(soup, 3, 24)\n",
    "\n",
    "total_episodes.append(episodes_4_int)\n",
    "total_viewers.append(viewers_4_float)\n",
    "total_dates.append(air_dates_4)\n",
    "\n",
    "# Extracting data for Season 5 (rows in Season's 5 table = 24)\n",
    "\n",
    "episodes_5_int = episodes(soup, 4, 24)\n",
    "viewers_5_float = viewers(soup, 4, 24)\n",
    "air_dates_5 = dates(soup, 4, 24)\n",
    "\n",
    "total_episodes.append(episodes_5_int)\n",
    "total_viewers.append(viewers_5_float)\n",
    "total_dates.append(air_dates_5)\n",
    "\n",
    "# Extracting data for Season 6 (rows in Season's 6 table = 24)\n",
    "\n",
    "episodes_6_int = episodes(soup, 5, 24)\n",
    "viewers_6_float = viewers(soup, 5, 24)\n",
    "air_dates_6 = dates(soup, 5, 24)\n",
    "\n",
    "total_episodes.append(episodes_6_int)\n",
    "total_viewers.append(viewers_6_float)\n",
    "total_dates.append(air_dates_6)\n",
    "\n",
    "# Extracting data for Season 7 (rows in Season's 7 table = 24)\n",
    "\n",
    "episodes_7_int = episodes(soup, 6, 24)\n",
    "viewers_7_float = viewers(soup, 6, 24)\n",
    "air_dates_7 = dates(soup, 6, 24)\n",
    "\n",
    "total_episodes.append(episodes_7_int)\n",
    "total_viewers.append(viewers_7_float)\n",
    "total_dates.append(air_dates_7)\n",
    "\n",
    "# Extracting data for Season 8 (rows in Season's 8 table = 24)\n",
    "\n",
    "episodes_8_int = episodes(soup, 7, 24)\n",
    "viewers_8_float = viewers(soup, 7, 24)\n",
    "air_dates_8 = dates(soup, 7, 24)\n",
    "\n",
    "total_episodes.append(episodes_8_int)\n",
    "total_viewers.append(viewers_8_float)\n",
    "total_dates.append(air_dates_8)\n",
    "\n",
    "# Extracting data for Season 9 (rows in Season's 9 table = 24)\n",
    "\n",
    "episodes_9_int = episodes(soup, 8, 24)\n",
    "viewers_9_float = viewers(soup, 8, 24)\n",
    "air_dates_9 = dates(soup, 8, 24)\n",
    "\n",
    "total_episodes.append(episodes_9_int)\n",
    "total_viewers.append(viewers_9_float)\n",
    "total_dates.append(air_dates_9)\n",
    "\n",
    "# Extracting data for Season 10 (rows in Season's 10 table = 24)\n",
    "\n",
    "episodes_10_int = episodes(soup, 9, 24)\n",
    "viewers_10_float = viewers(soup, 9, 24)\n",
    "air_dates_10 = dates(soup, 9, 24)\n",
    "\n",
    "total_episodes.append(episodes_10_int)\n",
    "total_viewers.append(viewers_10_float)\n",
    "total_dates.append(air_dates_10)\n",
    "\n",
    "# Extracting data for Season 11 (rows in Season's 11 table = 24)\n",
    "\n",
    "episodes_11_int = episodes(soup, 10, 24)\n",
    "viewers_11_float = viewers(soup, 10, 24)\n",
    "air_dates_11 = dates(soup, 10, 24)\n",
    "\n",
    "total_episodes.append(episodes_11_int)\n",
    "total_viewers.append(viewers_11_float)\n",
    "total_dates.append(air_dates_11)\n",
    "\n",
    "# Extracting data for Season 12 (rows in Season's 12 table = 24)\n",
    "\n",
    "episodes_12_int = episodes(soup, 11, 24)\n",
    "viewers_12_float = viewers(soup, 11, 24)\n",
    "air_dates_12 = dates(soup, 11, 24)\n",
    "\n",
    "total_episodes.append(episodes_12_int)\n",
    "total_viewers.append(viewers_12_float)\n",
    "total_dates.append(air_dates_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cda7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating each of the 3 total lists, in order to arrange them into a DataFrame\n",
    "\n",
    "total_episodes_flat = [item for element in total_episodes for item in element]\n",
    "total_viewers_flat = [item for element in total_viewers for item in element]\n",
    "total_dates_flat = [item for element in total_dates for item in element]\n",
    "\n",
    "total_episodes_array = np.array([total_episodes_flat])\n",
    "total_viewers_array = np.array([total_viewers_flat])\n",
    "total_dates_array = np.array([total_dates_flat])\n",
    "\n",
    "total_episodes_t = total_episodes_array.T\n",
    "total_viewers_t = total_viewers_array.T\n",
    "total_dates_t = total_dates_array.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d5df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into DataFrame and export as .csv file\n",
    "\n",
    "df_episodes = pd.DataFrame(total_episodes_t, columns=['Episode'])\n",
    "\n",
    "df_viewers = pd.DataFrame(total_viewers_t, columns=['Viewers (millions)'])\n",
    "\n",
    "df_dates = pd.DataFrame(total_dates_t, columns=['Air date'])\n",
    "df_dates['Air date'] = pd.to_datetime(df_dates['Air date'], format='%Y-%m-%d')\n",
    "\n",
    "pd.concat([df_episodes, df_viewers, df_dates], axis=1).to_csv(r'C:Your_own_path\\Scraping-results'r'.csv', index=False)  # Please substite your specific path for Jupyter projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415bc9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Episode\n",
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "..       ...\n",
      "274      275\n",
      "275      276\n",
      "276      277\n",
      "277      278\n",
      "278      279\n",
      "\n",
      "[279 rows x 1 columns]\n",
      "     Viewers (millions)\n",
      "0                  9.52\n",
      "1                  8.58\n",
      "2                  8.36\n",
      "3                  8.15\n",
      "4                  8.81\n",
      "..                  ...\n",
      "274               11.84\n",
      "275               12.48\n",
      "276               12.59\n",
      "277               18.52\n",
      "278               18.52\n",
      "\n",
      "[279 rows x 1 columns]\n",
      "      Air date\n",
      "0   2007-09-24\n",
      "1   2007-10-01\n",
      "2   2007-10-08\n",
      "3   2007-10-15\n",
      "4   2007-10-22\n",
      "..         ...\n",
      "274 2019-04-25\n",
      "275 2019-05-02\n",
      "276 2019-05-09\n",
      "277 2019-05-16\n",
      "278 2019-05-16\n",
      "\n",
      "[279 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Quick check of the resulting DataFrames, to verify if there is coherence with what we expected (279 rows per attribute)\n",
    "\n",
    "print(df_episodes)\n",
    "print(df_viewers)\n",
    "print(df_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f01caba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_766d7_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >Episode</th>\n",
       "      <th class=\"col_heading level0 col1\" >Viewers (millions)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Air date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_766d7_row0_col1\" class=\"data row0 col1\" >9.52</td>\n",
       "      <td id=\"T_766d7_row0_col2\" class=\"data row0 col2\" >2007-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_766d7_row1_col1\" class=\"data row1 col1\" >8.58</td>\n",
       "      <td id=\"T_766d7_row1_col2\" class=\"data row1 col2\" >2007-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_766d7_row2_col1\" class=\"data row2 col1\" >8.36</td>\n",
       "      <td id=\"T_766d7_row2_col2\" class=\"data row2 col2\" >2007-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_766d7_row3_col1\" class=\"data row3 col1\" >8.15</td>\n",
       "      <td id=\"T_766d7_row3_col2\" class=\"data row3 col2\" >2007-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_766d7_row4_col1\" class=\"data row4 col1\" >8.81</td>\n",
       "      <td id=\"T_766d7_row4_col2\" class=\"data row4 col2\" >2007-10-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_766d7_row5_col1\" class=\"data row5 col1\" >8.92</td>\n",
       "      <td id=\"T_766d7_row5_col2\" class=\"data row5 col2\" >2007-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_766d7_row6_col1\" class=\"data row6 col1\" >9.68</td>\n",
       "      <td id=\"T_766d7_row6_col2\" class=\"data row6 col2\" >2007-11-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_766d7_row7_col1\" class=\"data row7 col1\" >9.32</td>\n",
       "      <td id=\"T_766d7_row7_col2\" class=\"data row7 col2\" >2007-11-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row8_col0\" class=\"data row8 col0\" >9</td>\n",
       "      <td id=\"T_766d7_row8_col1\" class=\"data row8 col1\" >9.11</td>\n",
       "      <td id=\"T_766d7_row8_col2\" class=\"data row8 col2\" >2008-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_766d7_row9_col0\" class=\"data row9 col0\" >10</td>\n",
       "      <td id=\"T_766d7_row9_col1\" class=\"data row9 col1\" >8.63</td>\n",
       "      <td id=\"T_766d7_row9_col2\" class=\"data row9 col2\" >2008-03-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22d73393340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing and visualizing the scraped results\n",
    "\n",
    "df = pd.read_csv('Scraping-results.csv')\n",
    "df.head(10).style.hide_index().format(precision=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
